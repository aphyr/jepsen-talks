[2015-04-02 15:51:52,089][INFO ][node                     ] [n1] version[1.5.0], pid[31120], build[5448160/2015-03-23T14:30:58Z]
[2015-04-02 15:51:52,090][INFO ][node                     ] [n1] initializing ...
[2015-04-02 15:51:52,092][INFO ][plugins                  ] [n1] loaded [], sites []
[2015-04-02 15:51:54,149][INFO ][node                     ] [n1] initialized
[2015-04-02 15:51:54,149][INFO ][node                     ] [n1] starting ...
[2015-04-02 15:51:54,261][INFO ][transport                ] [n1] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/192.168.122.11:9300]}
[2015-04-02 15:51:54,272][INFO ][discovery                ] [n1] elasticsearch/JOZh0pFpRD-l519rJa7Wdg
[2015-04-02 15:51:57,331][INFO ][cluster.service          ] [n1] new_master [n1][JOZh0pFpRD-l519rJa7Wdg][n1][inet[/192.168.122.11:9300]], reason: zen-disco-join (elected_as_master)
[2015-04-02 15:51:57,358][INFO ][http                     ] [n1] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/192.168.122.11:9200]}
[2015-04-02 15:51:57,359][INFO ][node                     ] [n1] started
[2015-04-02 15:51:57,409][INFO ][cluster.service          ] [n1] added {[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-receive(join from node[[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]])
[2015-04-02 15:51:57,453][INFO ][cluster.service          ] [n1] added {[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-receive(join from node[[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 15:51:57,464][INFO ][cluster.service          ] [n1] added {[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]],[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(join from node[[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 15:51:57,560][INFO ][gateway                  ] [n1] recovered [0] indices into cluster_state
[2015-04-02 15:51:59,547][INFO ][cluster.metadata         ] [n1] [jepsen-index] creating index, cause [api], templates [], shards [5]/[4], mappings [number]
[2015-04-02 15:52:21,439][INFO ][cluster.service          ] [n1] removed {[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-node_failed([n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]), reason failed to ping, tried [3] times, each with maximum [3s] timeout
[2015-04-02 15:52:26,441][WARN ][discovery.zen.publish    ] [n1] timed out waiting for all nodes to process published state [15] (timeout [5s], pending nodes: [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]], [n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]], [n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 15:52:26,553][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:26,553][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:26,553][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:26,553][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:26,553][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:26,553][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:26,555][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] sending failed shard for [jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:26,555][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] sending failed shard for [jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:26,557][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] received shard failed for [jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:26,557][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] received shard failed for [jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:26,556][INFO ][cluster.service          ] [n1] removed {[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-node_failed([n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]), reason failed to ping, tried [3] times, each with maximum [3s] timeout
[2015-04-02 15:52:26,556][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] sending failed shard for [jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:26,557][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] received shard failed for [jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,559][WARN ][discovery.zen.publish    ] [n1] timed out waiting for all nodes to process published state [16] (timeout [5s], pending nodes: [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]], [n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 15:52:31,690][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:31,691][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:31,692][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:31,693][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:31,692][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[zS7SLydESTq7FFlMwnzFDw], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,694][WARN ][discovery.zen            ] [n1] not enough master nodes, current nodes: {[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]],[n1][JOZh0pFpRD-l519rJa7Wdg][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 15:52:31,692][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,692][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,691][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] sending failed shard for [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,691][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:31,695][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] received shard failed for [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,694][INFO ][cluster.service          ] [n1] removed {[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-node_failed([n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]), reason failed to ping, tried [3] times, each with maximum [3s] timeout
[2015-04-02 15:52:31,693][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,693][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,693][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [zS7SLydESTq7FFlMwnzFDw]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] disconnected
[2015-04-02 15:52:31,693][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] sending failed shard for [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,693][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:31,696][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] received shard failed for [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,695][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] sending failed shard for [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,697][WARN ][cluster.action.shard     ] [n1] [jepsen-index][1] received shard failed for [jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED], indexUUID [AEq_5IyxT9az98cz2yr35w], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 15:52:31,698][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,698][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,699][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:31,698][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:31,698][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,698][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:31,698][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[jexGpLfGRm-cyD-xF7ZuoA], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,698][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:31,699][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:31,699][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][1], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]. no master known.
[2015-04-02 15:52:31,699][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [jexGpLfGRm-cyD-xF7ZuoA]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] disconnected
[2015-04-02 15:52:31,699][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:52:31,699][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:52:31,698][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:52:31,702][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][1], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]. no master known.
[2015-04-02 15:52:31,701][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:31,700][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][1], node[jexGpLfGRm-cyD-xF7ZuoA], [R], s[STARTED]. no master known.
[2015-04-02 15:52:31,704][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][1], node[kn2YBFhJSrKmwd4KkZ_EgQ], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:31,704][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:31,705][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:31,705][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][1], node[zS7SLydESTq7FFlMwnzFDw], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:35,445][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [340] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:35,446][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [342] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:36,947][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [345] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:36,947][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [347] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:38,449][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [349] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:38,449][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [351] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:52:42,336][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [VDDIhU-sScSehftJ9rUxig]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [318] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:53:12,203][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:53:12,336][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [VDDIhU-sScSehftJ9rUxig]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [352] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:53:36,730][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:53:42,764][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:53:48,859][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:53:54,923][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:01,110][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:05,649][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [354] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:05,649][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [356] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:07,150][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [358] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:07,150][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [360] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:07,218][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:08,651][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [362] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:08,651][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [364] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:13,293][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:16,986][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[77], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,986][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[79], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,986][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[78], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,987][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]], id[77], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,987][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]], id[78], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,987][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]], id[79], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,988][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]], id[77], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,988][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]], id[79], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:16,989][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]], id[78], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:17,018][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]], id[80], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:17,018][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]], id[79], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:17,018][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]], id[81], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [3]
[2015-04-02 15:54:19,483][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:20,676][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [366] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:20,676][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [368] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:22,177][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [376] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:22,178][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [378] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:23,679][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [383] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:23,679][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [385] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:24,205][DEBUG][action.admin.cluster.state] [n1] no known master node, scheduling a retry
[2015-04-02 15:54:25,634][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:26,431][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], reason [ElasticsearchTimeoutException[Timeout waiting for task.]]
[2015-04-02 15:54:30,183][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [388] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:30,184][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [390] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:31,686][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [398] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:31,686][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [400] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:31,712][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:33,188][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [405] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:33,188][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [407] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:35,941][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], reason [ElasticsearchTimeoutException[Timeout waiting for task.]]
[2015-04-02 15:54:37,831][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:39,693][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [410] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:39,695][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [412] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:41,196][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [420] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:41,196][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [422] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:42,697][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [427] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:42,697][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [429] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:44,026][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:45,449][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], reason [ElasticsearchTimeoutException[Timeout waiting for task.]]
[2015-04-02 15:54:49,201][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [432] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:49,203][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [434] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:50,170][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:50,704][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [442] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:50,704][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [444] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:52,205][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [449] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:52,205][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [451] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:54,206][DEBUG][action.admin.cluster.state] [n1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2015-04-02 15:54:54,959][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], reason [ElasticsearchTimeoutException[Timeout waiting for task.]]
[2015-04-02 15:54:56,191][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:54:58,710][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [454] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:54:58,712][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [456] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:00,213][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [464] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:00,214][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [466] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:01,715][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [471] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:01,715][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [473] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:02,366][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:04,469][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], reason [ElasticsearchTimeoutException[Timeout waiting for task.]]
[2015-04-02 15:55:08,221][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [476] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:08,222][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [478] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:08,457][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:08,985][INFO ][cluster.service          ] [n1] new_master [n1][JOZh0pFpRD-l519rJa7Wdg][n1][inet[/192.168.122.11:9300]], reason: zen-disco-join (elected_as_master)
[2015-04-02 15:55:09,724][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [489] timed out after [3751ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:09,724][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [491] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:11,226][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[#zen_unicast_5#][n1][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [502] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:11,226][WARN ][discovery.zen.ping.unicast] [n1] failed to send ping to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/unicast] request_id [504] timed out after [3750ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 15:55:13,986][WARN ][discovery.zen.publish    ] [n1] timed out waiting for all nodes to process published state [17] (timeout [5s], pending nodes: [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 15:55:17,987][WARN ][discovery.zen            ] [n1] not enough master nodes, current nodes: {[n1][JOZh0pFpRD-l519rJa7Wdg][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 15:55:17,987][INFO ][cluster.service          ] [n1] removed {[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-node_failed([n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]), reason failed to ping, tried [3] times, each with maximum [3s] timeout
[2015-04-02 15:55:17,991][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:55:17,992][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[VDDIhU-sScSehftJ9rUxig], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@6f0638e]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,992][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[VDDIhU-sScSehftJ9rUxig], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@6f0638e]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,993][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,992][DEBUG][action.index             ] [n1] observer timed out. notifying listener. timeout setting [1m], time since start [2.7m]
[2015-04-02 15:55:17,992][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,991][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:55:17,994][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[VDDIhU-sScSehftJ9rUxig], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@6f0638e]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,995][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@6f0638e]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,994][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[VDDIhU-sScSehftJ9rUxig], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,994][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,994][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:55:17,994][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:55:17,994][DEBUG][action.index             ] [n1] observer timed out. notifying listener. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:17,993][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:55:17,993][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[VDDIhU-sScSehftJ9rUxig], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@6f0638e]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,993][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:55:17,993][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:55:17,992][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 15:55:17,997][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][1], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]. no master known.
[2015-04-02 15:55:17,995][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[VDDIhU-sScSehftJ9rUxig], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@3fddae2f]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 15:55:17,995][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]][jepsen-index][1]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 15:55:17,994][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [VDDIhU-sScSehftJ9rUxig]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] disconnected
[2015-04-02 15:55:17,994][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][1], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]. no master known.
[2015-04-02 15:55:17,999][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][1], node[VDDIhU-sScSehftJ9rUxig], [R], s[STARTED]. no master known.
[2015-04-02 15:55:20,647][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:26,715][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:32,808][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:38,924][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:45,111][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:51,255][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:55:57,260][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:03,426][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:09,456][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:15,574][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:21,641][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:27,728][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:33,919][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:40,016][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:46,169][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:48,102][INFO ][cluster.service          ] [n1] new_master [n1][JOZh0pFpRD-l519rJa7Wdg][n1][inet[/192.168.122.11:9300]], reason: zen-disco-join (elected_as_master)
[2015-04-02 15:56:52,251][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:56:58,357][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:57:02,649][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[116], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [10]
[2015-04-02 15:57:04,447][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 15:57:05,397][INFO ][cluster.service          ] [n1] added {[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-receive(join from node[[n4][kn2YBFhJSrKmwd4KkZ_EgQ][n4][inet[/192.168.122.14:9300]]])
[2015-04-02 15:57:05,447][INFO ][cluster.service          ] [n1] added {[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-receive(join from node[[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 15:57:05,468][INFO ][cluster.service          ] [n1] added {[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-receive(join from node[[n3][jexGpLfGRm-cyD-xF7ZuoA][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 15:57:10,198][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 15:57:43,281][INFO ][cluster.service          ] [n1] added {[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(join from node[[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 15:58:25,849][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[93], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [8]
[2015-04-02 15:58:25,850][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[117], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [10]
[2015-04-02 15:58:27,392][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[94], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [8]
[2015-04-02 15:58:27,393][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[118], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [10]
[2015-04-02 15:58:33,785][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[95], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [9]
[2015-04-02 15:58:35,321][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[99], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [9]
[2015-04-02 15:58:36,857][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], id[103], master [[n5][VDDIhU-sScSehftJ9rUxig][n5][inet[/192.168.122.15:9300]]], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [9]
[2015-04-02 15:58:49,891][INFO ][node                     ] [n1] stopping ...
[2015-04-02 15:58:49,901][INFO ][cluster.service          ] [n1] removed {[n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-node_left([n2][zS7SLydESTq7FFlMwnzFDw][n2][inet[/192.168.122.12:9300]])
[2015-04-02 15:58:50,057][INFO ][node                     ] [n1] stopped
[2015-04-02 15:58:50,057][INFO ][node                     ] [n1] closing ...
[2015-04-02 15:58:50,067][INFO ][node                     ] [n1] closed
[2015-04-02 16:38:27,911][INFO ][node                     ] [n1] version[1.5.0], pid[31865], build[5448160/2015-03-23T14:30:58Z]
[2015-04-02 16:38:27,912][INFO ][node                     ] [n1] initializing ...
[2015-04-02 16:38:27,915][INFO ][plugins                  ] [n1] loaded [], sites []
[2015-04-02 16:38:29,947][INFO ][node                     ] [n1] initialized
[2015-04-02 16:38:29,947][INFO ][node                     ] [n1] starting ...
[2015-04-02 16:38:30,060][INFO ][transport                ] [n1] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/192.168.122.11:9300]}
[2015-04-02 16:38:30,072][INFO ][discovery                ] [n1] elasticsearch/oZ_bAJHhRnO_hreyKHwyUg
[2015-04-02 16:38:33,287][INFO ][cluster.service          ] [n1] detected_master [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]], added {[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:38:33,305][INFO ][http                     ] [n1] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/192.168.122.11:9200]}
[2015-04-02 16:38:33,306][INFO ][node                     ] [n1] started
[2015-04-02 16:38:33,313][INFO ][cluster.service          ] [n1] added {[n4][y4UMunDiQ4W5Jbv2ezMo5A][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-receive(from master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:38:33,323][INFO ][cluster.service          ] [n1] added {[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-receive(from master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:38:33,422][INFO ][cluster.service          ] [n1] added {[n2][Rn-fxk43SUyaUFs94WoCtw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-receive(from master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:38:57,305][INFO ][discovery.zen            ] [n1] master_left [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]], reason [failed to ping, tried [3] times, each with  maximum [3s] timeout]
[2015-04-02 16:38:57,307][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [3] times, each with  maximum [3s] timeout), current nodes: {[n1][oZ_bAJHhRnO_hreyKHwyUg][n1][inet[/192.168.122.11:9300]],[n2][Rn-fxk43SUyaUFs94WoCtw][n2][inet[/192.168.122.12:9300]],[n4][y4UMunDiQ4W5Jbv2ezMo5A][n4][inet[/192.168.122.14:9300]],[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]],}
[2015-04-02 16:38:57,307][INFO ][cluster.service          ] [n1] removed {[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-master_failed ([n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]])
[2015-04-02 16:39:37,605][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:39:48,997][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:39:58,458][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:40:04,545][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:40:07,700][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:40:10,564][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:40:16,706][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:40:22,825][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:40:27,641][INFO ][cluster.service          ] [n1] detected_master [n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]], reason: zen-disco-receive(from master [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 16:40:37,798][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:40:57,280][INFO ][cluster.service          ] [n1] added {[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 16:41:10,679][INFO ][discovery.zen            ] [n1] master_left [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]], reason [failed to ping, tried [3] times, each with  maximum [3s] timeout]
[2015-04-02 16:41:10,679][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [3] times, each with  maximum [3s] timeout), current nodes: {[n1][oZ_bAJHhRnO_hreyKHwyUg][n1][inet[/192.168.122.11:9300]],[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]],[n2][Rn-fxk43SUyaUFs94WoCtw][n2][inet[/192.168.122.12:9300]],[n4][y4UMunDiQ4W5Jbv2ezMo5A][n4][inet[/192.168.122.14:9300]],}
[2015-04-02 16:41:10,680][INFO ][cluster.service          ] [n1] removed {[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-master_failed ([n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]])
[2015-04-02 16:41:10,685][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]][jepsen-index][2]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:41:10,685][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][2], node[7gbvfc-EQTu1rJZH2HimPQ], [R], s[STARTED]. no master known.
[2015-04-02 16:41:51,002][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:42:11,803][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:42:17,850][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:42:21,103][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:42:23,866][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:42:29,908][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:42:35,958][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:42:41,119][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]], reason [RemoteTransportException[[n5][inet[/192.168.122.15:9300]][internal:discovery/zen/join]]; nested: ElasticsearchIllegalStateException[Node [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]] not master for join request from [[n1][oZ_bAJHhRnO_hreyKHwyUg][n1][inet[/192.168.122.11:9300]]]]; ], tried [3] times
[2015-04-02 16:42:41,546][INFO ][cluster.service          ] [n1] detected_master [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]], reason: zen-disco-receive(from master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:42:46,639][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [4093ms] ago, timed out [1093ms] ago, action [internal:discovery/zen/fd/master_ping], node [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]], id [436]
[2015-04-02 16:42:51,136][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:43:09,162][INFO ][cluster.service          ] [n1] added {[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-receive(from master [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:43:11,225][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]], id[106], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [4]
[2015-04-02 16:43:11,226][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]], id[108], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [4]
[2015-04-02 16:43:32,680][INFO ][discovery.zen            ] [n1] master_left [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]], reason [failed to ping, tried [3] times, each with  maximum [3s] timeout]
[2015-04-02 16:43:32,681][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [3] times, each with  maximum [3s] timeout), current nodes: {[n1][oZ_bAJHhRnO_hreyKHwyUg][n1][inet[/192.168.122.11:9300]],[n2][Rn-fxk43SUyaUFs94WoCtw][n2][inet[/192.168.122.12:9300]],[n4][y4UMunDiQ4W5Jbv2ezMo5A][n4][inet[/192.168.122.14:9300]],[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]],}
[2015-04-02 16:43:32,682][INFO ][cluster.service          ] [n1] removed {[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-master_failed ([n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]])
[2015-04-02 16:43:32,686][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]][jepsen-index][2]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:43:32,686][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]][jepsen-index][2]
org.elasticsearch.transport.NodeDisconnectedException: [n5][inet[/192.168.122.15:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:43:32,686][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][2], node[0a1qisL5QMCKGna70SR45w], [R], s[STARTED]. no master known.
[2015-04-02 16:43:32,686][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][2], node[0a1qisL5QMCKGna70SR45w], [R], s[STARTED]. no master known.
[2015-04-02 16:44:12,904][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:44:34,380][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:44:43,001][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:45:03,118][INFO ][discovery.zen            ] [n1] failed to send join request to master [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]], reason [RemoteTransportException[[n3][inet[/192.168.122.13:9300]][internal:discovery/zen/join]]; nested: ElasticsearchIllegalStateException[Node [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]] not master for join request from [[n1][oZ_bAJHhRnO_hreyKHwyUg][n1][inet[/192.168.122.11:9300]]]]; ], tried [3] times
[2015-04-02 16:45:03,421][INFO ][cluster.service          ] [n1] detected_master [n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]], reason: zen-disco-receive(from master [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 16:45:13,102][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:45:33,157][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]], id[187], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [6]
[2015-04-02 16:45:33,157][WARN ][discovery.zen.ping.multicast] [n1] received ping response ping_response{node [[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]]], id[189], master [null], hasJoinedOnce [true], cluster_name[elasticsearch]} with no matching id [6]
[2015-04-02 16:45:59,622][INFO ][cluster.service          ] [n1] added {[n5][0a1qisL5QMCKGna70SR45w][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n3][7gbvfc-EQTu1rJZH2HimPQ][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 16:46:25,203][INFO ][node                     ] [n1] stopping ...
[2015-04-02 16:46:25,248][INFO ][node                     ] [n1] stopped
[2015-04-02 16:46:25,248][INFO ][node                     ] [n1] closing ...
[2015-04-02 16:46:25,254][INFO ][node                     ] [n1] closed
[2015-04-02 16:48:10,672][INFO ][node                     ] [n1] version[1.5.0], pid[32559], build[5448160/2015-03-23T14:30:58Z]
[2015-04-02 16:48:10,673][INFO ][node                     ] [n1] initializing ...
[2015-04-02 16:48:10,675][INFO ][plugins                  ] [n1] loaded [], sites []
[2015-04-02 16:48:12,750][INFO ][node                     ] [n1] initialized
[2015-04-02 16:48:12,750][INFO ][node                     ] [n1] starting ...
[2015-04-02 16:48:12,906][INFO ][transport                ] [n1] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/192.168.122.11:9300]}
[2015-04-02 16:48:12,918][INFO ][discovery                ] [n1] elasticsearch/PqcFd_gHQDWpBFuccZ8SEw
[2015-04-02 16:48:16,198][INFO ][cluster.service          ] [n1] detected_master [n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]], added {[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]],[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]],[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]],[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:48:16,272][INFO ][http                     ] [n1] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/192.168.122.11:9200]}
[2015-04-02 16:48:16,272][INFO ][node                     ] [n1] started
[2015-04-02 16:48:33,215][INFO ][discovery.zen            ] [n1] master_left [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], reason [failed to ping, tried [2] times, each with  maximum [1s] timeout]
[2015-04-02 16:48:33,216][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [2] times, each with  maximum [1s] timeout), current nodes: {[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]],[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]],[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]],[n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 16:48:33,216][INFO ][cluster.service          ] [n1] removed {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-master_failed ([n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]])
[2015-04-02 16:49:13,453][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:49:34,403][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:49:40,493][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:49:43,550][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:49:46,509][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:49:52,515][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:49:58,561][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 16:50:03,465][INFO ][cluster.service          ] [n1] new_master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]], reason: zen-disco-join (elected_as_master)
[2015-04-02 16:50:13,646][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:50:43,686][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]
org.elasticsearch.transport.ConnectTransportException: [n5][inet[/192.168.122.15:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.15:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 16:50:48,061][INFO ][cluster.service          ] [n1] added {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(join from node[[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]])
[2015-04-02 16:51:18,665][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [615] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:18,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [616] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:18,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [618] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:18,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [617] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:21,527][WARN ][gateway.local            ] [n1] [jepsen-index][4]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [600] timed out after [30000ms]
	... 4 more
[2015-04-02 16:51:21,528][WARN ][gateway.local            ] [n1] [jepsen-index][4]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [601] timed out after [30000ms]
	... 4 more
[2015-04-02 16:51:21,529][WARN ][gateway.local            ] [n1] [jepsen-index][4]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [602] timed out after [30000ms]
	... 4 more
[2015-04-02 16:51:48,665][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [644] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:48,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [645] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:48,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [647] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:48,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [646] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:51:51,531][WARN ][gateway.local            ] [n1] [jepsen-index][4]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [637] timed out after [30001ms]
	... 4 more
[2015-04-02 16:51:51,533][WARN ][gateway.local            ] [n1] [jepsen-index][4]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [638] timed out after [30000ms]
	... 4 more
[2015-04-02 16:51:51,534][WARN ][gateway.local            ] [n1] [jepsen-index][4]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [639] timed out after [30000ms]
	... 4 more
[2015-04-02 16:52:18,665][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [675] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:18,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [676] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:18,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [678] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:18,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [677] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:21,536][WARN ][gateway.local            ] [n1] [jepsen-index][0]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [668] timed out after [30000ms]
	... 4 more
[2015-04-02 16:52:21,538][WARN ][gateway.local            ] [n1] [jepsen-index][0]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [669] timed out after [30000ms]
	... 4 more
[2015-04-02 16:52:21,542][WARN ][gateway.local            ] [n1] [jepsen-index][0]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [670] timed out after [30000ms]
	... 4 more
[2015-04-02 16:52:48,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [709] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:48,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [710] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:48,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [711] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [712] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:52:51,544][WARN ][gateway.local            ] [n1] [jepsen-index][0]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [698] timed out after [30000ms]
	... 4 more
[2015-04-02 16:52:51,545][WARN ][gateway.local            ] [n1] [jepsen-index][0]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [699] timed out after [30000ms]
	... 4 more
[2015-04-02 16:52:51,546][WARN ][gateway.local            ] [n1] [jepsen-index][0]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [700] timed out after [30000ms]
	... 4 more
[2015-04-02 16:53:18,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [744] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:18,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [745] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:18,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [747] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:18,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [746] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:21,548][WARN ][gateway.local            ] [n1] [jepsen-index][3]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [734] timed out after [30001ms]
	... 4 more
[2015-04-02 16:53:21,550][WARN ][gateway.local            ] [n1] [jepsen-index][3]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [735] timed out after [30000ms]
	... 4 more
[2015-04-02 16:53:21,551][WARN ][gateway.local            ] [n1] [jepsen-index][3]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [736] timed out after [30000ms]
	... 4 more
[2015-04-02 16:53:48,666][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [781] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [783] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [784] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [782] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:53:51,553][WARN ][gateway.local            ] [n1] [jepsen-index][3]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [778] timed out after [30000ms]
	... 4 more
[2015-04-02 16:53:51,555][WARN ][gateway.local            ] [n1] [jepsen-index][3]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [779] timed out after [30001ms]
	... 4 more
[2015-04-02 16:53:51,558][WARN ][gateway.local            ] [n1] [jepsen-index][3]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [780] timed out after [30000ms]
	... 4 more
[2015-04-02 16:54:18,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [803] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [804] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [806] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [805] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:21,560][WARN ][gateway.local            ] [n1] [jepsen-index][1]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [800] timed out after [30001ms]
	... 4 more
[2015-04-02 16:54:21,562][WARN ][gateway.local            ] [n1] [jepsen-index][1]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [801] timed out after [30000ms]
	... 4 more
[2015-04-02 16:54:21,566][WARN ][gateway.local            ] [n1] [jepsen-index][1]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [802] timed out after [30000ms]
	... 4 more
[2015-04-02 16:54:48,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [825] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [826] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [828] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:48,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [827] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:54:51,568][WARN ][gateway.local            ] [n1] [jepsen-index][1]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [822] timed out after [30000ms]
	... 4 more
[2015-04-02 16:54:51,570][WARN ][gateway.local            ] [n1] [jepsen-index][1]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [823] timed out after [30000ms]
	... 4 more
[2015-04-02 16:54:51,570][WARN ][gateway.local            ] [n1] [jepsen-index][1]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [824] timed out after [30001ms]
	... 4 more
[2015-04-02 16:55:18,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [850] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [851] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [853] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [852] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:21,573][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [847] timed out after [30000ms]
	... 4 more
[2015-04-02 16:55:21,575][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [848] timed out after [30001ms]
	... 4 more
[2015-04-02 16:55:21,578][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [849] timed out after [30000ms]
	... 4 more
[2015-04-02 16:55:48,667][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [aXLTEQEGQGu8OYZ8xg4j6g]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n4][inet[/192.168.122.14:9300]][cluster:monitor/nodes/stats[n]] request_id [883] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:48,669][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [884] timed out after [15000ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:48,669][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [886] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:48,669][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [885] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:55:51,580][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.action.FailedNodeException: Failed node [HtOne1mjRoqMKIa111JIqw]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [875] timed out after [30000ms]
	... 4 more
[2015-04-02 16:55:51,581][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.action.FailedNodeException: Failed node [azLv1KuLQXCnXR7K5dgq9Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [876] timed out after [30000ms]
	... 4 more
[2015-04-02 16:55:51,582][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [877] timed out after [30001ms]
	... 4 more
[2015-04-02 16:55:51,589][INFO ][cluster.service          ] [n1] removed {[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-node_failed([n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]), reason failed to ping, tried [2] times, each with maximum [1s] timeout
[2015-04-02 16:55:51,732][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,732][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@263249ab]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,733][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,733][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@724732fb]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,733][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1038dcad]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,734][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@724732fb]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,734][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1038dcad]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,735][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@304145d]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,736][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@27f143e9]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,736][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5ca178da]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,734][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,734][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@263249ab]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,734][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1038dcad]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,734][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52aa95c6]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,733][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]][jepsen-index][3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1e21dfe1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,733][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@188686a3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,733][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@27f143e9]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,739][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@263249ab]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,739][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]][jepsen-index][3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:55:51,739][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5ca178da]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,739][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1e21dfe1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@304145d]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@724732fb]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1038dcad]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52aa95c6]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@724732fb]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] sending failed shard for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@188686a3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52aa95c6]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@263249ab]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,738][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]][jepsen-index][3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:55:51,738][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1e21dfe1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@188686a3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@304145d]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@41f13c3b]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@27f143e9]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5ca178da]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@27f143e9]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,737][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@724732fb]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,736][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52aa95c6]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,736][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]][jepsen-index][3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:55:51,736][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@188686a3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,736][DEBUG][action.index             ] [n1] observer timed out. notifying listener. timeout setting [1m], time since start [2.7m]
[2015-04-02 16:55:51,736][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@41f13c3b]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,736][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@304145d]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,735][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1e21dfe1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,735][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@41f13c3b]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,735][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@52aa95c6]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,746][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] sending failed shard for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,743][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] sending failed shard for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,742][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] received shard failed for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,741][DEBUG][action.index             ] [n1] observer timed out. notifying listener. timeout setting [1m], time since start [3.4m]
[2015-04-02 16:55:51,741][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5ca178da]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,741][DEBUG][action.index             ] [n1] observer timed out. notifying listener. timeout setting [1m], time since start [4.4m]
[2015-04-02 16:55:51,741][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@41f13c3b]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,741][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][0], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1038dcad]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][1], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@41f13c3b]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@1e21dfe1]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.index             ] [n1] observer timed out. notifying listener. timeout setting [1m], time since start [4.8m]
[2015-04-02 16:55:51,740][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][4], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@263249ab]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@304145d]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@5ca178da]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,740][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] sending failed shard for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,751][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] received shard failed for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,740][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,739][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][2], node[aXLTEQEGQGu8OYZ8xg4j6g], [P], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@188686a3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,739][DEBUG][action.admin.indices.stats] [n1] [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]: failed to execute [org.elasticsearch.action.admin.indices.stats.IndicesStatsRequest@27f143e9]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:monitor/stats[s]] disconnected
[2015-04-02 16:55:51,739][WARN ][discovery.zen.ping.multicast] [n1] failed to receive confirmation on sent ping response to [[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]]]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][internal:discovery/zen/multicast] disconnected
[2015-04-02 16:55:51,739][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]][jepsen-index][3]
org.elasticsearch.transport.NodeDisconnectedException: [n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 16:55:51,748][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] received shard failed for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,748][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] received shard failed for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,753][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] sending failed shard for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:55:51,753][WARN ][cluster.action.shard     ] [n1] [jepsen-index][3] received shard failed for [jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED], indexUUID [sM21o4vwQx28pSVfow-d4Q], reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]
[2015-04-02 16:56:18,668][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [HtOne1mjRoqMKIa111JIqw]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n5][inet[/192.168.122.15:9300]][cluster:monitor/nodes/stats[n]] request_id [930] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:18,669][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][cluster:monitor/nodes/stats[n]] request_id [932] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:18,669][DEBUG][action.admin.cluster.node.stats] [n1] failed to execute on node [azLv1KuLQXCnXR7K5dgq9Q]
org.elasticsearch.transport.ReceiveTimeoutTransportException: [n3][inet[/192.168.122.13:9300]][cluster:monitor/nodes/stats[n]] request_id [931] timed out after [15001ms]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:19,002][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329464ms] ago, timed out [328464ms] ago, action [internal:discovery/zen/fd/ping], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [591]
[2015-04-02 16:56:19,002][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329482ms] ago, timed out [328482ms] ago, action [internal:discovery/zen/fd/ping], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [589]
[2015-04-02 16:56:19,003][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [328465ms] ago, timed out [327464ms] ago, action [internal:discovery/zen/fd/ping], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [596]
[2015-04-02 16:56:19,003][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [328482ms] ago, timed out [327482ms] ago, action [internal:discovery/zen/fd/ping], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [595]
[2015-04-02 16:56:19,003][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [27414ms] ago, timed out [26413ms] ago, action [internal:discovery/zen/fd/ping], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [910]
[2015-04-02 16:56:19,003][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [27413ms] ago, timed out [26413ms] ago, action [internal:discovery/zen/fd/ping], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [911]
[2015-04-02 16:56:19,003][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [26413ms] ago, timed out [25413ms] ago, action [internal:discovery/zen/fd/ping], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [922]
[2015-04-02 16:56:19,003][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [26413ms] ago, timed out [25413ms] ago, action [internal:discovery/zen/fd/ping], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [923]
[2015-04-02 16:56:19,514][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329448ms] ago, timed out [328447ms] ago, action [internal:discovery/zen/fd/ping], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [592]
[2015-04-02 16:56:19,515][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [328448ms] ago, timed out [327448ms] ago, action [internal:discovery/zen/fd/ping], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [597]
[2015-04-02 16:56:19,515][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [27925ms] ago, timed out [26925ms] ago, action [internal:discovery/zen/fd/ping], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [912]
[2015-04-02 16:56:19,515][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [26925ms] ago, timed out [25925ms] ago, action [internal:discovery/zen/fd/ping], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [924]
[2015-04-02 16:56:20,035][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [196369ms] ago, timed out [181368ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [746]
[2015-04-02 16:56:20,036][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [106368ms] ago, timed out [91368ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [827]
[2015-04-02 16:56:20,036][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [298505ms] ago, timed out [268505ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [638]
[2015-04-02 16:56:20,036][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [88464ms] ago, timed out [58463ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [848]
[2015-04-02 16:56:20,037][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [238494ms] ago, timed out [208494ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [699]
[2015-04-02 16:56:21,051][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329525ms] ago, timed out [299525ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [601]
[2015-04-02 16:56:21,051][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329525ms] ago, timed out [299525ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [600]
[2015-04-02 16:56:21,051][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [227384ms] ago, timed out [212383ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [712]
[2015-04-02 16:56:21,052][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [287386ms] ago, timed out [272386ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [646]
[2015-04-02 16:56:21,052][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [197386ms] ago, timed out [182385ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [745]
[2015-04-02 16:56:21,052][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [197385ms] ago, timed out [182385ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [747]
[2015-04-02 16:56:21,052][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [287386ms] ago, timed out [272386ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [645]
[2015-04-02 16:56:21,053][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [167386ms] ago, timed out [152385ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [784]
[2015-04-02 16:56:21,053][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [47385ms] ago, timed out [32384ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [885]
[2015-04-02 16:56:21,053][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [17385ms] ago, timed out [2384ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [931]
[2015-04-02 16:56:21,054][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [149494ms] ago, timed out [119494ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [802]
[2015-04-02 16:56:21,055][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [17387ms] ago, timed out [2386ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [930]
[2015-04-02 16:56:21,057][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [209509ms] ago, timed out [179509ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [736]
[2015-04-02 16:56:21,058][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329532ms] ago, timed out [299532ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [602]
[2015-04-02 16:56:21,058][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [299527ms] ago, timed out [269527ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [639]
[2015-04-02 16:56:21,058][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [149499ms] ago, timed out [119498ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [800]
[2015-04-02 16:56:21,066][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [269530ms] ago, timed out [239530ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [670]
[2015-04-02 16:56:21,066][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [179513ms] ago, timed out [149513ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [780]
[2015-04-02 16:56:21,563][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [137896ms] ago, timed out [122896ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [804]
[2015-04-02 16:56:21,564][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [89992ms] ago, timed out [59992ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [847]
[2015-04-02 16:56:21,564][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [270029ms] ago, timed out [240029ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [668]
[2015-04-02 16:56:21,743][WARN ][gateway.local            ] [n1] [jepsen-index][2]: failed to list shard stores on node [WHVm-JBQSwmch8h97rVD4Q]
org.elasticsearch.action.FailedNodeException: Failed node [WHVm-JBQSwmch8h97rVD4Q]
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.onFailure(TransportNodesOperationAction.java:206)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction.access$1000(TransportNodesOperationAction.java:97)
	at org.elasticsearch.action.support.nodes.TransportNodesOperationAction$AsyncAction$4.handleException(TransportNodesOperationAction.java:178)
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:531)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.transport.ReceiveTimeoutTransportException: [n2][inet[/192.168.122.12:9300]][internal:cluster/nodes/indices/shard/store[n]] request_id [916] timed out after [30001ms]
	... 4 more
[2015-04-02 16:56:22,588][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [271052ms] ago, timed out [241052ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [669]
[2015-04-02 16:56:22,589][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [181037ms] ago, timed out [151036ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [779]
[2015-04-02 16:56:22,590][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [138922ms] ago, timed out [123922ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [806]
[2015-04-02 16:56:22,591][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [121024ms] ago, timed out [91023ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [824]
[2015-04-02 16:56:23,098][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [259432ms] ago, timed out [244432ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [676]
[2015-04-02 16:56:23,099][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [79432ms] ago, timed out [64431ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [851]
[2015-04-02 16:56:23,103][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [121536ms] ago, timed out [91536ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [822]
[2015-04-02 16:56:24,123][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [260457ms] ago, timed out [245457ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [678]
[2015-04-02 16:56:24,124][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [290458ms] ago, timed out [275458ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [647]
[2015-04-02 16:56:24,124][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [230457ms] ago, timed out [215457ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [711]
[2015-04-02 16:56:24,124][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [170457ms] ago, timed out [155456ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [783]
[2015-04-02 16:56:24,125][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [212577ms] ago, timed out [182577ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [735]
[2015-04-02 16:56:24,126][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [110458ms] ago, timed out [95458ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [828]
[2015-04-02 16:56:24,126][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [92553ms] ago, timed out [62553ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [849]
[2015-04-02 16:56:24,128][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [152568ms] ago, timed out [122568ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [801]
[2015-04-02 16:56:24,636][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [110968ms] ago, timed out [95968ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [826]
[2015-04-02 16:56:24,636][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [50968ms] ago, timed out [35968ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [884]
[2015-04-02 16:56:24,637][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [63058ms] ago, timed out [33058ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [875]
[2015-04-02 16:56:24,637][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [243094ms] ago, timed out [213094ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [698]
[2015-04-02 16:56:25,149][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [81481ms] ago, timed out [66481ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [852]
[2015-04-02 16:56:25,150][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [63571ms] ago, timed out [33571ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [876]
[2015-04-02 16:56:26,184][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [22516ms] ago, timed out [7515ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [932]
[2015-04-02 16:56:26,185][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [82517ms] ago, timed out [67517ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [853]
[2015-04-02 16:56:26,185][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [64606ms] ago, timed out [34605ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [877]
[2015-04-02 16:56:33,338][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329672ms] ago, timed out [314672ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [616]
[2015-04-02 16:56:33,338][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329672ms] ago, timed out [314672ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [617]
[2015-04-02 16:56:33,338][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329672ms] ago, timed out [314672ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [618]
[2015-04-02 16:56:33,339][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [239672ms] ago, timed out [224672ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [710]
[2015-04-02 16:56:33,339][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [269673ms] ago, timed out [254673ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [677]
[2015-04-02 16:56:33,340][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [191788ms] ago, timed out [161788ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [778]
[2015-04-02 16:56:33,340][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [149673ms] ago, timed out [134672ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [805]
[2015-04-02 16:56:33,348][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [59680ms] ago, timed out [44679ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [886]
[2015-04-02 16:56:33,350][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [41608ms] ago, timed out [11607ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [916]
[2015-04-02 16:56:33,351][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [131784ms] ago, timed out [101784ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]], id [823]
[2015-04-02 16:56:33,351][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [251808ms] ago, timed out [221808ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]], id [700]
[2015-04-02 16:56:51,259][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [329729ms] ago, timed out [299728ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [637]
[2015-04-02 16:56:51,260][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [197593ms] ago, timed out [182592ms] ago, action [cluster:monitor/nodes/stats[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [782]
[2015-04-02 16:56:51,261][WARN ][transport                ] [n1] Received response for a request that has timed out, sent [239714ms] ago, timed out [209713ms] ago, action [internal:cluster/nodes/indices/shard/store[n]], node [[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]]], id [734]
[2015-04-02 16:56:51,301][INFO ][cluster.service          ] [n1] removed {[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-node_failed([n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]]), reason failed to ping, tried [2] times, each with maximum [1s] timeout
[2015-04-02 16:56:51,418][WARN ][discovery.zen            ] [n1] not enough master nodes, current nodes: {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],[n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 16:56:51,419][INFO ][cluster.service          ] [n1] removed {[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-node_failed([n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]), reason failed to ping, tried [2] times, each with maximum [1s] timeout
[2015-04-02 16:56:51,424][WARN ][discovery.zen            ] [n1] received a request to rejoin the cluster from [WHVm-JBQSwmch8h97rVD4Q], current nodes: {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],[n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 16:56:51,426][WARN ][discovery.zen            ] [n1] received a request to rejoin the cluster from [WHVm-JBQSwmch8h97rVD4Q], current nodes: {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],[n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 16:56:51,427][WARN ][discovery.zen            ] [n1] received a request to rejoin the cluster from [WHVm-JBQSwmch8h97rVD4Q], current nodes: {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],[n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]],}
[2015-04-02 16:56:51,427][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-started ([jepsen-index][0], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-started ([jepsen-index][0], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,428][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-started ([jepsen-index][1], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-started ([jepsen-index][1], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,431][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-started ([jepsen-index][0], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-started ([jepsen-index][0], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,431][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-started ([jepsen-index][1], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-started ([jepsen-index][1], node[HtOne1mjRoqMKIa111JIqw], [R], s[INITIALIZING]), reason [master [n1][PqcFd_gHQDWpBFuccZ8SEw][n1][inet[/192.168.122.11:9300]] marked shard as initializing, but shard state is [STARTED], mark shard as started]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,432][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,432][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,433][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,433][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:51,433][ERROR][cluster.action.shard     ] [n1] unexpected failure during [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
org.elasticsearch.common.util.concurrent.EsRejectedExecutionException: no longer master. source: [shard-failed ([jepsen-index][3], node[aXLTEQEGQGu8OYZ8xg4j6g], [R], s[STARTED]), reason [Failed to perform [indices:data/write/index] on replica, message [NodeDisconnectedException[[n4][inet[/192.168.122.14:9300]][indices:data/write/index[r]] disconnected]]]]
	at org.elasticsearch.cluster.ClusterStateUpdateTask.onNoLongerMaster(ClusterStateUpdateTask.java:52)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:360)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:188)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
[2015-04-02 16:56:54,438][INFO ][cluster.service          ] [n1] master {new [n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]}, removed {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],}, added {[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]],[n3][azLv1KuLQXCnXR7K5dgq9Q][n3][inet[/192.168.122.13:9300]],[n4][aXLTEQEGQGu8OYZ8xg4j6g][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-receive(from master [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 16:56:54,653][INFO ][cluster.service          ] [n1] added {[n5][HtOne1mjRoqMKIa111JIqw][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n2][WHVm-JBQSwmch8h97rVD4Q][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 16:57:10,790][INFO ][node                     ] [n1] stopping ...
[2015-04-02 16:57:10,840][INFO ][node                     ] [n1] stopped
[2015-04-02 16:57:10,841][INFO ][node                     ] [n1] closing ...
[2015-04-02 16:57:10,849][INFO ][node                     ] [n1] closed
[2015-04-02 17:11:18,151][INFO ][node                     ] [n1] version[1.5.0], pid[33325], build[5448160/2015-03-23T14:30:58Z]
[2015-04-02 17:11:18,152][INFO ][node                     ] [n1] initializing ...
[2015-04-02 17:11:18,154][INFO ][plugins                  ] [n1] loaded [], sites []
[2015-04-02 17:11:20,208][INFO ][node                     ] [n1] initialized
[2015-04-02 17:11:20,209][INFO ][node                     ] [n1] starting ...
[2015-04-02 17:11:20,320][INFO ][transport                ] [n1] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/192.168.122.11:9300]}
[2015-04-02 17:11:20,332][INFO ][discovery                ] [n1] elasticsearch/wfeDLniDRyWWH4c8yiK_bg
[2015-04-02 17:11:23,754][INFO ][cluster.service          ] [n1] detected_master [n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]], added {[n4][n6wxZq_dRzShrGu7NOMUBA][n4][inet[/192.168.122.14:9300]],[n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]],[n2][1NJ_1e7aQv-Q0lp8vhHs8w][n2][inet[/192.168.122.12:9300]],[n5][gyRsIUeeRdaTLiy0GeEqPA][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 17:11:23,811][INFO ][http                     ] [n1] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/192.168.122.11:9200]}
[2015-04-02 17:11:23,811][INFO ][node                     ] [n1] started
[2015-04-02 17:11:40,771][INFO ][discovery.zen            ] [n1] master_left [[n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]]], reason [failed to ping, tried [2] times, each with  maximum [1s] timeout]
[2015-04-02 17:11:40,772][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [2] times, each with  maximum [1s] timeout), current nodes: {[n4][n6wxZq_dRzShrGu7NOMUBA][n4][inet[/192.168.122.14:9300]],[n1][wfeDLniDRyWWH4c8yiK_bg][n1][inet[/192.168.122.11:9300]],[n2][1NJ_1e7aQv-Q0lp8vhHs8w][n2][inet[/192.168.122.12:9300]],[n5][gyRsIUeeRdaTLiy0GeEqPA][n5][inet[/192.168.122.15:9300]],}
[2015-04-02 17:11:40,772][INFO ][cluster.service          ] [n1] removed {[n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-master_failed ([n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]])
[2015-04-02 17:11:40,778][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]][jepsen-index][3]
org.elasticsearch.transport.NodeDisconnectedException: [n3][inet[/192.168.122.13:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 17:11:40,780][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][3], node[161TIY9ET22h-FCHKovuFQ], [R], s[STARTED]. no master known.
[2015-04-02 17:12:20,963][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:12:41,964][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:12:48,062][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:12:50,975][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:12:54,081][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:13:11,059][INFO ][cluster.service          ] [n1] detected_master [n2][1NJ_1e7aQv-Q0lp8vhHs8w][n2][inet[/192.168.122.12:9300]], reason: zen-disco-receive(from master [[n2][1NJ_1e7aQv-Q0lp8vhHs8w][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 17:13:21,063][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:13:51,107][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]]
org.elasticsearch.transport.ConnectTransportException: [n3][inet[/192.168.122.13:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.13:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:15:07,976][INFO ][cluster.service          ] [n1] added {[n3][161TIY9ET22h-FCHKovuFQ][n3][inet[/192.168.122.13:9300]],}, reason: zen-disco-receive(from master [[n2][1NJ_1e7aQv-Q0lp8vhHs8w][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 17:15:30,903][INFO ][node                     ] [n1] stopping ...
[2015-04-02 17:15:30,951][INFO ][node                     ] [n1] stopped
[2015-04-02 17:15:30,951][INFO ][node                     ] [n1] closing ...
[2015-04-02 17:15:30,957][INFO ][node                     ] [n1] closed
[2015-04-02 17:18:10,693][INFO ][node                     ] [n1] version[1.5.0], pid[33930], build[5448160/2015-03-23T14:30:58Z]
[2015-04-02 17:18:10,693][INFO ][node                     ] [n1] initializing ...
[2015-04-02 17:18:10,696][INFO ][plugins                  ] [n1] loaded [], sites []
[2015-04-02 17:18:12,831][INFO ][node                     ] [n1] initialized
[2015-04-02 17:18:12,832][INFO ][node                     ] [n1] starting ...
[2015-04-02 17:18:13,004][INFO ][transport                ] [n1] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/192.168.122.11:9300]}
[2015-04-02 17:18:13,020][INFO ][discovery                ] [n1] elasticsearch/e1wr10rDQuuy1v0Hpkg4BQ
[2015-04-02 17:18:16,200][INFO ][cluster.service          ] [n1] detected_master [n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]], added {[n3][5ZOwcZMCT9qQs1SmF_t_Tg][n3][inet[/192.168.122.13:9300]],[n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]],[n4][UekzsX3xTgK-RrFqImlj7w][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-receive(from master [[n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 17:18:16,217][INFO ][http                     ] [n1] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/192.168.122.11:9200]}
[2015-04-02 17:18:16,217][INFO ][node                     ] [n1] started
[2015-04-02 17:18:21,272][INFO ][cluster.service          ] [n1] added {[n5][UEMg-5qtT9eZL6tyvhyEvg][n5][inet[/192.168.122.15:9300]],}, reason: zen-disco-receive(from master [[n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 17:18:38,221][INFO ][discovery.zen            ] [n1] master_left [[n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]], reason [failed to ping, tried [2] times, each with  maximum [1s] timeout]
[2015-04-02 17:18:38,222][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [2] times, each with  maximum [1s] timeout), current nodes: {[n5][UEMg-5qtT9eZL6tyvhyEvg][n5][inet[/192.168.122.15:9300]],[n3][5ZOwcZMCT9qQs1SmF_t_Tg][n3][inet[/192.168.122.13:9300]],[n1][e1wr10rDQuuy1v0Hpkg4BQ][n1][inet[/192.168.122.11:9300]],[n4][UekzsX3xTgK-RrFqImlj7w][n4][inet[/192.168.122.14:9300]],}
[2015-04-02 17:18:38,223][INFO ][cluster.service          ] [n1] removed {[n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-master_failed ([n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]])
[2015-04-02 17:19:18,441][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:19:39,212][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:19:45,288][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:19:48,538][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:19:51,336][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:20:08,433][INFO ][cluster.service          ] [n1] detected_master [n3][5ZOwcZMCT9qQs1SmF_t_Tg][n3][inet[/192.168.122.13:9300]], reason: zen-disco-receive(from master [[n3][5ZOwcZMCT9qQs1SmF_t_Tg][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 17:20:18,640][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:20:48,680][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:20:53,114][INFO ][cluster.service          ] [n1] added {[n2][0b5wcgcXTQCXZWnWC_wd3g][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-receive(from master [[n3][5ZOwcZMCT9qQs1SmF_t_Tg][n3][inet[/192.168.122.13:9300]]])
[2015-04-02 17:22:21,559][INFO ][node                     ] [n1] stopping ...
[2015-04-02 17:22:21,613][INFO ][node                     ] [n1] stopped
[2015-04-02 17:22:21,613][INFO ][node                     ] [n1] closing ...
[2015-04-02 17:22:21,620][INFO ][node                     ] [n1] closed
[2015-04-02 17:23:15,267][INFO ][node                     ] [n1] version[1.5.0], pid[34532], build[5448160/2015-03-23T14:30:58Z]
[2015-04-02 17:23:15,268][INFO ][node                     ] [n1] initializing ...
[2015-04-02 17:23:15,271][INFO ][plugins                  ] [n1] loaded [], sites []
[2015-04-02 17:23:17,365][INFO ][node                     ] [n1] initialized
[2015-04-02 17:23:17,365][INFO ][node                     ] [n1] starting ...
[2015-04-02 17:23:17,540][INFO ][transport                ] [n1] bound_address {inet[/0.0.0.0:9300]}, publish_address {inet[/192.168.122.11:9300]}
[2015-04-02 17:23:17,553][INFO ][discovery                ] [n1] elasticsearch/RFSSB6jdSiibAp4KPOOUkw
[2015-04-02 17:23:20,851][INFO ][cluster.service          ] [n1] detected_master [n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]], added {[n3][PPO-q-TjRWKz4KeWbraZrQ][n3][inet[/192.168.122.13:9300]],[n5][fTAVHoCsQO6VUibMXmtXsQ][n5][inet[/192.168.122.15:9300]],[n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]],[n4][L9XMeohBRi6HBuNvBgXJgQ][n4][inet[/192.168.122.14:9300]],}, reason: zen-disco-receive(from master [[n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]]])
[2015-04-02 17:23:20,910][INFO ][http                     ] [n1] bound_address {inet[/0.0.0.0:9200]}, publish_address {inet[/192.168.122.11:9200]}
[2015-04-02 17:23:20,910][INFO ][node                     ] [n1] started
[2015-04-02 17:23:37,869][INFO ][discovery.zen            ] [n1] master_left [[n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]]], reason [failed to ping, tried [2] times, each with  maximum [1s] timeout]
[2015-04-02 17:23:37,870][WARN ][discovery.zen            ] [n1] master left (reason = failed to ping, tried [2] times, each with  maximum [1s] timeout), current nodes: {[n3][PPO-q-TjRWKz4KeWbraZrQ][n3][inet[/192.168.122.13:9300]],[n5][fTAVHoCsQO6VUibMXmtXsQ][n5][inet[/192.168.122.15:9300]],[n1][RFSSB6jdSiibAp4KPOOUkw][n1][inet[/192.168.122.11:9300]],[n4][L9XMeohBRi6HBuNvBgXJgQ][n4][inet[/192.168.122.14:9300]],}
[2015-04-02 17:23:37,870][INFO ][cluster.service          ] [n1] removed {[n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-master_failed ([n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]])
[2015-04-02 17:23:37,875][WARN ][action.index             ] [n1] Failed to perform indices:data/write/index on remote replica [n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]][jepsen-index][0]
org.elasticsearch.transport.NodeDisconnectedException: [n2][inet[/192.168.122.12:9300]][indices:data/write/index[r]] disconnected
[2015-04-02 17:23:37,876][WARN ][cluster.action.shard     ] [n1] can't send shard failed for [jepsen-index][0], node[C5eUbynVQcmsC4GmVlqTNw], [R], s[STARTED]. no master known.
[2015-04-02 17:24:18,086][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:24:38,933][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:24:44,965][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:24:48,185][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:24:50,964][DEBUG][action.index             ] [n1] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2015-04-02 17:25:08,028][INFO ][cluster.service          ] [n1] detected_master [n4][L9XMeohBRi6HBuNvBgXJgQ][n4][inet[/192.168.122.14:9300]], reason: zen-disco-receive(from master [[n4][L9XMeohBRi6HBuNvBgXJgQ][n4][inet[/192.168.122.14:9300]]])
[2015-04-02 17:25:18,287][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:25:48,330][WARN ][discovery.zen.ping.multicast] [n1] failed to connect to requesting node [n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]]
org.elasticsearch.transport.ConnectTransportException: [n2][inet[/192.168.122.12:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:797)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:731)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:704)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:216)
	at org.elasticsearch.discovery.zen.ping.multicast.MulticastZenPing$Receiver$1.run(MulticastZenPing.java:542)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
Caused by: org.elasticsearch.common.netty.channel.ConnectTimeoutException: connection timed out: /192.168.122.12:9300
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processConnectTimeout(NioClientBoss.java:139)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:83)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[2015-04-02 17:25:52,717][INFO ][cluster.service          ] [n1] added {[n2][C5eUbynVQcmsC4GmVlqTNw][n2][inet[/192.168.122.12:9300]],}, reason: zen-disco-receive(from master [[n4][L9XMeohBRi6HBuNvBgXJgQ][n4][inet[/192.168.122.14:9300]]])
[2015-04-02 17:27:19,734][INFO ][node                     ] [n1] stopping ...
[2015-04-02 17:27:19,782][INFO ][node                     ] [n1] stopped
[2015-04-02 17:27:19,783][INFO ][node                     ] [n1] closing ...
